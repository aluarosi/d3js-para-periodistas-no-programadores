{
  "version": "0.0.6",
  "name": "stream-transform",
  "description": "Object transformations implementing the Node.js `stream.Transform` API",
  "keywords": [
    "stream",
    "transform",
    "csv",
    "object"
  ],
  "licenses": [
    {
      "type": "BSD",
      "url": "https://github.com/wdavidw/node-stream-transform/blob/master/LICENSE"
    }
  ],
  "repository": {
    "type": "git",
    "url": "http://www.github.com/wdavidw/node-stream-transform"
  },
  "dependencies": {},
  "devDependencies": {
    "coffee-script": "latest",
    "pad": "latest",
    "mocha": "latest",
    "csv-generate": "latest",
    "should": "latest"
  },
  "optionalDependencies": {},
  "main": "./lib",
  "scripts": {
    "test": "make test"
  },
  "readme": "[![Build Status](https://secure.travis-ci.org/wdavidw/node-stream-transform.png)][travis]\n\nThis project provides a simple object transformation framework implementing the \nNode.js `stream.Transform` API. It was originally developed as a part of the Node.js \n[CSV package][csv] (`npm install csv`) and can be used independently.\n\n[Documentation for the stream-transform package is available here][transform].\n\n*   Simple callback based API\n*   Node.js [stream.Transform][streamtransform] API, pipe through it\n*   synchronous versus asynchronous user callbacks\n*   Accept object, array or JSON as input and output\n*   Sequential or user-defined concurrent execution\n*   Skip and create new records\n*   Alter or clone input data\n\n## Usage\n\nRun `npm install csv` to install the full CSV module or run \n`npm install stream-transform` if you are only interested by this package.\n\nCallback API: `transform(udf, [options])`   \n\nStream API: `transform(data, [options], udf, [options], [callback])`   \n\nUse the callback style API for simplicity or the stream based API for \nscalability or mix the 2 APIs.\n\nFor examples, refer to below examples, [the \"samples\" folder][stream-samples], \nthe documentation or [the \"test\" folder][stream-test].\n\n## Synchronous versus asynchronous execution\n\nThe mode is defined by the signature of transformation function. It is expected\nto run synchronously when it declares only one argument, the data to \ntransform. It is expected to run asynchronously when it declares two arguments,\nthe data to transform and the callback to be called once the transformed data\nis ready.\n\nIn synchronous mode, you may simply return the altered data or throw an error.\nIn asynchronous mode, you must call the provided callback with 2 arguments, the\nerror if any and the altered data.\n\n## Array versus objects\n\nThe transformation function may either receive arrays or objects.\n\nIf you specify the `columns` read option, the `row` argument will be \nprovided as an object with keys matching columns names. Otherwise it\nwill be provided as an array.\n\n## Sequential versus concurrent execution\n\nBy sequential, we mean only 1 transformation function is running at a given\ntime. By concurrent, we mean a maximum of x functions are running in parrallel. \nThe number of running functions is defined by the \"parallel\" option. When set to\n\"1\", the mode is sequential, when above \"1\", it defines the maximum of running \nfunctions. Note, this only affect asynchronous executions.\n\n## Skipping and creating records\n\nSkipping records is easily achieved by returning null in synchonous mode or\npassing null to the callback handler in asynchonous mode. Generating multiple\nrecords is only supported in asynchonous mode by providing n-arguments after the\nerror argument instead of simply one.\n\n## Altering or cloning the provided data\n\nThe data recieved inside the transformation function is the original data and is\nnot modified nor cloned. Depending on which api you choose, it may be provided \nin the constructor or send to the `write` function. If you wish to not alter the\noriginal data, it is your responsibility to send a new data in your\ntransformation function instead of the original modified data.\n\n## Examples\n\n### Using the callback API\n\nThe transformer receive a string and return an array inside a user-provided \ncallback. This example is available with the command `node samples/callback.js`.\n\n```javascript\nvar transform = require('stream-transform');\nvar should = require('should');\n\ntransform([\n  ['1','2','3','4'],\n  ['a','b','c','d']\n], function(data){\n  data.push(data.shift())\n  return data;\n}, function(err, output){\n  output.should.eql([ [ '2', '3', '4', '1' ], [ 'b', 'c', 'd', 'a' ] ]);\n});\n```\n\n### Using the stream API\n\nCSV data is send through the `write` function and the resulted data is obtained\nwithin the \"readable\" event by calling the `read` function. This example is \navailable with the command `node samples/stream.js`.\n\n```javascript\nvar transform = require('stream-transform');\nvar should = require('should');\n\nvar output = [];\nvar transformer = transform(function(data){\n  data.push(data.shift())\n  return data;\n});\ntransformer.on('readable', function(){\n  while(row = transformer.read()){\n    output.push(row);\n  }\n});\ntransformer.on('error', function(err){\n  console.log(err.message);\n});\ntransformer.on('finish', function(){\n  output.should.eql([ [ '2', '3', '4', '1' ], [ 'b', 'c', 'd', 'a' ] ]);\n});\ntransformer.write(['1','2','3','4']);\ntransformer.write(['a','b','c','d']);\ntransformer.end();\n```\n\n### Using synchronous transformation\n\nYou may run this script with the command `node samples/synchronous.js`.\n\nThe transformation function is run synchronously because is only expect one \nargument, the data to be transformed. It is expected to return the transformed\ndata or to throw an error.\n    \n```javascript\nvar transform = require('stream-transform');\n\ntransform([\n  ['1','2','3','4'],\n  ['a','b','c','d']\n], function(data){\n  data.push(data.shift());\n  return data.join(',')+'\\n';\n})\n.pipe(process.stdout);\n\n// Output:\n// 2,3,4,1\n// b,c,d,a\n```\n\n### Using asynchronous transformation\n\nYou may run this script with the command `node samples/asynchronous.js`.\n\nThe transformation callback is requesting two arguments, the data to transform\nand the callback to call once the data is ready.\n\nThe transformation callback is exected concurrently with a maximum of 20 \nparallel executions.\n\n```javascript\nvar transform = require('stream-transform');\n\ntransform([\n  ['1','2','3','4'],\n  ['a','b','c','d']\n], function(data, callback){\n  setImmediate(function(){\n    data.push(data.shift());\n    callback(null, data.join(',')+'\\n');\n  });\n}, {parallel: 20})\n.pipe(process.stdout);\n\n// Output:\n// 2,3,4,1\n// b,c,d,a\n```\n\n## Development\n\nTests are executed with mocha. To install it, simple run `npm install` \nfollowed by `npm test`. It will install mocha and its dependencies in your \nproject \"node_modules\" directory and run the test suite. The tests run \nagainst the CoffeeScript source files.\n\nTo generate the JavaScript files, run `make build`.\n\nThe test suite is run online with [Travis][travis] against the versions \n0.9, 0.10 and 0.11 of Node.js.\n\n## Contributors\n\n*\t  David Worms: <https://github.com/wdavidw>\n\n[streamtransform]: http://nodejs.org/api/stream.html#stream_class_stream_transform\n[transform]: https://github.com/wdavidw/node-stream-transform\n[csv]: https://github.com/wdavidw/node-csv\n[stream-samples]: https://github.com/wdavidw/node-stream-transform/tree/master/samples\n[stream-test]: https://github.com/wdavidw/node-stream-transform/tree/master/test\n[travis]: http://travis-ci.org/wdavidw/node-stream-transform\n\n",
  "readmeFilename": "README.md",
  "_id": "stream-transform@0.0.6",
  "_shasum": "365aa2beffe68cfaa96cb4c525f8644befc3d037",
  "_from": "stream-transform@*",
  "_resolved": "https://registry.npmjs.org/stream-transform/-/stream-transform-0.0.6.tgz"
}
